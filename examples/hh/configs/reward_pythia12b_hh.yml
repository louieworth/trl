model_name_or_path: EleutherAI/pythia-1.4b
output_dir: "reward_modeling_anthropic_hh"
per_device_train_batch_size: 64
num_train_epochs: 1
gradient_accumulation_steps: 16
gradient_checkpointing: True
learning_rate: 1.41e-5
report_to: "wandb"
remove_unused_columns: False
optim: "adamw_torch"
logging_steps: 100
evaluation_strategy: "steps"
max_length: 512
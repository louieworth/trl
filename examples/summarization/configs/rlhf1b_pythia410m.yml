model_name: mnoukhov/pythia410m-tldr-sft
reward_adapter_name: mnoukhov/tldr_gptrm1b_pythia410m_fp16_1epoch
gold_model_name: mnoukhov/pythia1b-sft-rm-tldrprompt
steps: 10000
load_in_8bit: False
bf16: False
fp16: True
learning_rate: 1e-5
lora_all_linear: True
lora_r: 8
lora_alpha: 32
lora_dropout: 0.
gradient_accumulation_steps: 4
mini_batch_size: 8
batch_size: 32
eval_steps: 10
input_ids_input: False
strip_prompt: True
